{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27c304e6-67f0-48ff-8eff-aeb5537488c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "QUaA\n",
      "(300, 1024)\n",
      "[[ 84. 202. 125. ... 156.  36. 147.]\n",
      " [ 94. 200. 129. ... 148.  58.  94.]\n",
      " [ 68. 208. 123. ... 171.  63. 141.]\n",
      " ...\n",
      " [156. 170. 146. ...  98.  51. 140.]\n",
      " [103. 202. 144. ...  91.   0. 240.]\n",
      " [ 55. 213. 114. ... 102.  83. 156.]]\n",
      "(300, 128)\n",
      "[[ 39. 232. 159. ... 255.   0. 113.]\n",
      " [  0. 255. 162. ... 157. 255. 255.]\n",
      " [ 16. 255. 147. ... 207. 255. 202.]\n",
      " ...\n",
      " [ 21. 255. 122. ... 228.  80.   0.]\n",
      " [ 59. 188. 217. ... 255.   0.  45.]\n",
      " [ 77. 162. 208. ... 255.   0.  27.]]\n",
      "2\n",
      "5TaA\n",
      "(300, 1024)\n",
      "[[  0.  72. 173. ... 142. 119. 137.]\n",
      " [114. 131.  41. ...  69. 175. 255.]\n",
      " [139. 113.  28. ... 178. 248. 178.]\n",
      " ...\n",
      " [234. 161. 150. ... 165.   5.   0.]\n",
      " [216. 172. 161. ...  10.  24. 179.]\n",
      " [148. 189. 119. ... 150. 129.  29.]]\n",
      "(300, 128)\n",
      "[[145.  75. 101. ... 255. 167. 204.]\n",
      " [184.  69.  98. ...  91.  66. 152.]\n",
      " [191.  76.  86. ... 100. 129. 207.]\n",
      " ...\n",
      " [148. 127. 227. ... 212. 162. 138.]\n",
      " [ 75.  86. 215. ... 128. 213.  24.]\n",
      " [ 82.  83. 235. ...  50.   0. 241.]]\n",
      "3\n",
      "RQaA\n",
      "(167, 1024)\n",
      "[[170. 209.  63. ... 181.  62.  98.]\n",
      " [169. 173.  53. ... 240. 115.  40.]\n",
      " [221. 179.  78. ... 185.   0.  31.]\n",
      " ...\n",
      " [191. 144.  71. ... 251. 103. 192.]\n",
      " [176. 127.  48. ... 221. 112. 131.]\n",
      " [190. 153.  76. ... 118. 156. 137.]]\n",
      "(167, 128)\n",
      "[[ 58. 137. 153. ... 179. 255.  36.]\n",
      " [ 47. 140. 203. ...  46.  73. 179.]\n",
      " [ 57. 130. 188. ...   0. 147. 137.]\n",
      " ...\n",
      " [ 95. 118. 200. ...   0. 180.   0.]\n",
      " [ 81. 104. 195. ... 147.  19. 236.]\n",
      " [ 53. 174. 176. ...   0. 255. 126.]]\n",
      "4\n",
      "SYaA\n",
      "(152, 1024)\n",
      "[[  0.  72. 173. ... 142. 119. 137.]\n",
      " [  0. 106. 128. ... 163.  91.  77.]\n",
      " [ 59. 197. 165. ... 130. 221. 155.]\n",
      " ...\n",
      " [ 47. 213. 141. ... 155. 201. 153.]\n",
      " [ 51. 197. 187. ... 106. 154. 126.]\n",
      " [  0.  72. 174. ... 121. 127. 151.]]\n",
      "(152, 128)\n",
      "[[169.  46. 116. ... 105.  90. 199.]\n",
      " [164.  57. 108. ...  90.  27. 222.]\n",
      " [173.  70. 113. ... 201. 219. 227.]\n",
      " ...\n",
      " [148.  40. 140. ... 136. 208.  77.]\n",
      " [149.  45. 132. ... 216. 126. 109.]\n",
      " [172.  28. 131. ... 212.  32. 217.]]\n",
      "5\n",
      "ibaA\n",
      "(300, 1024)\n",
      "[[  0.  72. 173. ... 142. 119. 137.]\n",
      " [123. 126.  38. ... 204.  80. 119.]\n",
      " [141.  97.  35. ... 188.  65. 142.]\n",
      " ...\n",
      " [144. 183. 110. ... 158. 147.   0.]\n",
      " [132. 177. 109. ...  73. 255. 107.]\n",
      " [140. 172. 119. ... 151.  50.   0.]]\n",
      "(300, 128)\n",
      "[[ 97. 115. 111. ... 166. 183.  66.]\n",
      " [ 44. 252.  75. ... 134. 255. 255.]\n",
      " [ 82. 169. 112. ...  54. 160. 253.]\n",
      " ...\n",
      " [ 69.  87. 195. ... 189. 194. 137.]\n",
      " [ 95.  48. 207. ... 228. 255.  92.]\n",
      " [111.  57. 195. ... 255. 152. 109.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def parse_sequence_example(example_proto):\n",
    "    context_features = {\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'labels': tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    sequence_features = {\n",
    "        'rgb': tf.io.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "        'audio': tf.io.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "    }\n",
    "\n",
    "    return tf.io.parse_sequence_example(example_proto, context_features, sequence_features)\n",
    "\n",
    "\n",
    "\n",
    "file_name=\"train0026\"\n",
    "dataset_path=\"data/yt8m/\"\n",
    "random_id=\"ORaA\"\n",
    "yt8m_path = os.path.join(dataset_path, f\"frame/{file_name}.tfrecord\")\n",
    "dataset = tf.data.TFRecordDataset(yt8m_path)\n",
    "parsed_dataset = dataset.map(parse_sequence_example)\n",
    "num=1\n",
    "for example in parsed_dataset.take(5):\n",
    "    #if random_id == example[0]['id'].numpy().decode('utf-8'):\n",
    "    print(num)\n",
    "    num+=1\n",
    "    print(example[0]['id'].numpy().decode('utf-8'))\n",
    "    label_indices = example[0]['labels'].values\n",
    "    features = tf.cast(tf.io.decode_raw(example[1]['rgb'], tf.uint8), tf.float32).numpy()\n",
    "    audio =  tf.cast(tf.io.decode_raw(example[1]['audio'], tf.uint8), tf.float32).numpy()\n",
    "    print(features.shape)\n",
    "    print(features)\n",
    "    print(audio.shape)\n",
    "    print(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1c7a1b9-f58a-4ddc-ad10-1b2a9ef11fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c1576c8-1492-4c18-97cc-ea2b73a5bd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'labels': SparseTensorSpec(TensorShape([None]), tf.int64), 'id': TensorSpec(shape=(), dtype=tf.string, name=None)}, {'audio': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'rgb': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, {'audio': TensorSpec(shape=(), dtype=tf.int64, name=None), 'rgb': TensorSpec(shape=(), dtype=tf.int64, name=None)})\n"
     ]
    }
   ],
   "source": [
    "print(parsed_dataset.element_spec)\n",
    "for example in parsed_dataset:\n",
    "    #print(example[1]['rgb'])\n",
    "    features = tf.cast(tf.io.decode_raw(example[1]['rgb'], tf.uint8), tf.float32).numpy()\n",
    "    audio =  tf.cast(tf.io.decode_raw(example[1]['audio'], tf.uint8), tf.float32).numpy()\n",
    "    #print(features.shape)\n",
    "    #print(audio.shape)\n",
    "    #print(features)\n",
    "    #print(audio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42fe62e3-9c26-4d7d-bdfa-78190a45b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 1\n",
      "Context Features:\n",
      "  labels: [  0 874]\n",
      "  id: b'QUaA'\n",
      "\n",
      "Sequence Features:\n",
      "  audio: (300,)\n",
      "  rgb: (300,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def parse_sequence_example(example_proto):\n",
    "    context_features = {\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'labels': tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    sequence_features = {\n",
    "        'rgb': tf.io.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "        'audio': tf.io.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "    }\n",
    "    context, sequence, _ = tf.io.parse_sequence_example(\n",
    "        example_proto,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "    return context, sequence\n",
    "\n",
    "# 檔案路徑\n",
    "file_name = \"train0026\"\n",
    "dataset_path = \"data/yt8m/\"\n",
    "yt8m_path = os.path.join(dataset_path, f\"frame/{file_name}.tfrecord\")\n",
    "\n",
    "# 加載並解析數據集\n",
    "dataset = tf.data.TFRecordDataset(yt8m_path).map(parse_sequence_example)\n",
    "\n",
    "# 查看結構\n",
    "for num, (context, sequence) in enumerate(dataset.take(1), 1):\n",
    "    print(f\"Record {num}\")\n",
    "    \n",
    "    print(\"Context Features:\")\n",
    "    for key, value in context.items():\n",
    "        if isinstance(value, tf.SparseTensor):\n",
    "            value = tf.sparse.to_dense(value)  # 將 SparseTensor 轉換為 Tensor\n",
    "        print(f\"  {key}: {value.numpy()}\")\n",
    "\n",
    "    print(\"\\nSequence Features:\")\n",
    "    for key, value in sequence.items():\n",
    "        if isinstance(value, tf.SparseTensor):\n",
    "            value = tf.sparse.to_dense(value)  # 將 SparseTensor 轉換為 Tensor\n",
    "        print(f\"  {key}: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffe04615-f46a-4fe3-9032-0402b0ca1987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 1:\n",
      "\n",
      "Context Features:\n",
      "  labels: [  0 874]\n",
      "  id: b'QUaA'\n",
      "\n",
      "Sequence Features:\n",
      "  audio:\n",
      "    Length: 300\n",
      "    First Element Shape: (128,)\n",
      "    First Element (raw): [ 39 232 159 255 246  98  99 255 252 213]\n",
      "  rgb:\n",
      "    Length: 300\n",
      "    First Element Shape: (1024,)\n",
      "    First Element (raw): [ 84 202 125 181 134  50 219  90 206  44]\n",
      "--------------------------------------------------\n",
      "Record 2:\n",
      "\n",
      "Context Features:\n",
      "  labels: [ 26 194 445 782]\n",
      "  id: b'5TaA'\n",
      "\n",
      "Sequence Features:\n",
      "  audio:\n",
      "    Length: 300\n",
      "    First Element Shape: (128,)\n",
      "    First Element (raw): [145  75 101 159 127 118  84  44 136  73]\n",
      "  rgb:\n",
      "    Length: 300\n",
      "    First Element Shape: (1024,)\n",
      "    First Element (raw): [  0  72 173  30   0   0  41  33 199 132]\n",
      "--------------------------------------------------\n",
      "Record 3:\n",
      "\n",
      "Context Features:\n",
      "  labels: [1493]\n",
      "  id: b'RQaA'\n",
      "\n",
      "Sequence Features:\n",
      "  audio:\n",
      "    Length: 167\n",
      "    First Element Shape: (128,)\n",
      "    First Element (raw): [ 58 137 153  84 245 114 176 159 241 131]\n",
      "  rgb:\n",
      "    Length: 167\n",
      "    First Element Shape: (1024,)\n",
      "    First Element (raw): [170 209  63  40 122 158 164 129 223 119]\n",
      "--------------------------------------------------\n",
      "Record 4:\n",
      "\n",
      "Context Features:\n",
      "  labels: [ 31  40  47  57 117]\n",
      "  id: b'SYaA'\n",
      "\n",
      "Sequence Features:\n",
      "  audio:\n",
      "    Length: 152\n",
      "    First Element Shape: (128,)\n",
      "    First Element (raw): [169  46 116 105 116  94 166 210 164  88]\n",
      "  rgb:\n",
      "    Length: 152\n",
      "    First Element Shape: (1024,)\n",
      "    First Element (raw): [  0  72 173  30   0   0  41  33 199 132]\n",
      "--------------------------------------------------\n",
      "Record 5:\n",
      "\n",
      "Context Features:\n",
      "  labels: [15 18 67]\n",
      "  id: b'ibaA'\n",
      "\n",
      "Sequence Features:\n",
      "  audio:\n",
      "    Length: 300\n",
      "    First Element Shape: (128,)\n",
      "    First Element (raw): [ 97 115 111 110   0  34 255  47 255 140]\n",
      "  rgb:\n",
      "    Length: 300\n",
      "    First Element Shape: (1024,)\n",
      "    First Element (raw): [  0  72 173  30   0   0  41  33 199 132]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def parse_and_display_tfrecord(file_path, max_records=5):\n",
    "    \"\"\"\n",
    "    解析並顯示 TFRecord 中的所有內容，包括 context 和 sequence features。\n",
    "    :param file_path: TFRecord 文件的路徑\n",
    "    :param max_records: 要顯示的記錄數\n",
    "    \"\"\"\n",
    "    # 定義 context 和 sequence features 的格式\n",
    "    context_features = {\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'labels': tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    sequence_features = {\n",
    "        'rgb': tf.io.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "        'audio': tf.io.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "    }\n",
    "\n",
    "    def parse_sequence_example(example_proto):\n",
    "        # 解析 SequenceExample\n",
    "        context, sequence, _ = tf.io.parse_sequence_example(\n",
    "            example_proto,\n",
    "            context_features=context_features,\n",
    "            sequence_features=sequence_features\n",
    "        )\n",
    "        return context, sequence\n",
    "\n",
    "    # 加載 TFRecord 文件\n",
    "    dataset = tf.data.TFRecordDataset(file_path).map(parse_sequence_example)\n",
    "\n",
    "    # 遍歷每條記錄並顯示內容\n",
    "    for num, (context, sequence) in enumerate(dataset.take(max_records), 1):\n",
    "        print(f\"Record {num}:\\n\")\n",
    "        \n",
    "        print(\"Context Features:\")\n",
    "        for key, value in context.items():\n",
    "            if isinstance(value, tf.SparseTensor):\n",
    "                value = tf.sparse.to_dense(value)\n",
    "            print(f\"  {key}: {value.numpy()}\")\n",
    "\n",
    "        print(\"\\nSequence Features:\")\n",
    "        for key, value in sequence.items():\n",
    "            # 解碼字節數據並顯示形狀\n",
    "            decoded_values = [tf.io.decode_raw(v, tf.uint8).numpy() for v in value]\n",
    "            print(f\"  {key}:\")\n",
    "            print(f\"    Length: {len(decoded_values)}\")\n",
    "            print(f\"    First Element Shape: {decoded_values[0].shape if decoded_values else 'N/A'}\")\n",
    "            print(f\"    First Element (raw): {decoded_values[0][:10] if decoded_values else 'N/A'}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 替換為您的 TFRecord 文件路徑\n",
    "file_path = yt8m_path\n",
    "parse_and_display_tfrecord(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "347a8fe8-b061-4ef6-9734-116698f99f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55024/3255376464.py:4: RuntimeWarning: Unexpected end-group tag: Not all data was converted\n",
      "  print(tf.train.SequenceExample.FromString(sequence_example))\n"
     ]
    }
   ],
   "source": [
    "# 确保读取文件时使用二进制模式\n",
    "with open(yt8m_path, \"rb\") as f:\n",
    "    sequence_example = f.read()\n",
    "    print(tf.train.SequenceExample.FromString(sequence_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af50ab4b-03cd-4804-b018-1b7aad4c649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析 SequenceExample 出错: 'utf-8' codec can't decode byte 0xd5 in position 9: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "from google.protobuf import text_format\n",
    "from tensorflow.core.example import example_pb2  # 导入 SequenceExample 的 protobuf 定义\n",
    "\n",
    "try:\n",
    "    seq_example = example_pb2.SequenceExample()\n",
    "    text_format.Parse(sequence_example, seq_example)  # 尝试解析数据\n",
    "    print(seq_example)  # 打印解析后的结构\n",
    "except Exception as e:\n",
    "    print(f\"解析 SequenceExample 出错: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c866849-8e0b-4881-838a-efae9e2c747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the file: video_1\n",
      "Data in video_1: <HDF5 group \"/video_1\" (1 members)>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# 讀取 .h5 檔案\n",
    "file_path = 'dataset/mr_hisum.h5'\n",
    "with h5py.File(file_path, 'r') as h5_file:\n",
    "    # 列出所有資料集\n",
    "    print(\"Keys in the file:\", list(h5_file.keys())[0])\n",
    "    \n",
    "    # 讀取某個資料集\n",
    "    dataset_name = list(h5_file.keys())[0]  # 假設第一個 key\n",
    "    data = h5_file[dataset_name]\n",
    "    print(f\"Data in {dataset_name}:\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e198b4-1edb-4c16-8ec3-789c98c92aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from video_2/change_points:\n",
      "[[  0   5]\n",
      " [  5   8]\n",
      " [  8  11]\n",
      " [ 11  14]\n",
      " [ 14  17]\n",
      " [ 17  20]\n",
      " [ 20  23]\n",
      " [ 23  27]\n",
      " [ 27  34]\n",
      " [ 34  36]\n",
      " [ 36  54]\n",
      " [ 54  63]\n",
      " [ 63  66]\n",
      " [ 66  69]\n",
      " [ 69  71]\n",
      " [ 71  74]\n",
      " [ 74  77]\n",
      " [ 77  78]\n",
      " [ 78  83]\n",
      " [ 83  89]\n",
      " [ 89  93]\n",
      " [ 93  97]\n",
      " [ 97  99]\n",
      " [ 99 101]\n",
      " [101 110]\n",
      " [110 119]\n",
      " [119 125]\n",
      " [125 136]]\n",
      "(28, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "Data from video_2/gt_summary:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(137,)\n",
      "<class 'numpy.ndarray'>\n",
      "Data from video_2/gtscore:\n",
      "[0.09690889 0.09690889 0.08694464 0.11213095 0.11213095 0.09550747\n",
      " 0.03781535 0.03677416 0.03677416 0.02538695 0.02958781 0.02992466\n",
      " 0.02992466 0.05142312 0.05419752 0.05419752 0.01339526 0.01905386\n",
      " 0.02036059 0.02036059 0.0217012  0.02353164 0.03344904 0.03344904\n",
      " 0.06553965 0.03372766 0.03372766 0.02896433 0.03842754 0.04890942\n",
      " 0.04890942 0.06123905 0.07634136 0.12762352 0.12762352 0.14270445\n",
      " 0.12665586 0.12058642 0.12058642 0.09799883 0.09684225 0.09684225\n",
      " 0.08411987 0.07857414 0.07798627 0.07798627 0.07922448 0.07808215\n",
      " 0.0732513  0.0732513  0.07447107 0.07452788 0.07452788 0.08079201\n",
      " 0.08453188 0.0858019  0.0858019  0.08277155 0.07301576 0.06510047\n",
      " 0.06510047 0.05415466 0.0475137  0.0475137  0.03590622 0.03535342\n",
      " 0.02686716 0.02686716 0.02815499 0.02646838 0.02343649 0.02343649\n",
      " 0.02592393 0.03953634 0.0439486  0.0439486  0.01738615 0.01998784\n",
      " 0.01998784 0.02067048 0.02014819 0.02146628 0.02146628 0.01438433\n",
      " 0.01633356 0.01376838 0.01376838 0.01248945 0.00995783 0.00995783\n",
      " 0.01256694 0.0100076  0.01329225 0.01329225 0.00940967 0.01137218\n",
      " 0.0075005  0.0075005  0.00755353 0.00757248 0.00757248 0.00631022\n",
      " 0.00633658 0.0083118  0.0083118  0.00637049 0.0057597  0.00510745\n",
      " 0.00510745 0.00448886 0.00647983 0.         0.         0.00293607\n",
      " 0.01770124 0.01770124 0.84638084 0.99466406 1.         1.\n",
      " 0.91157585 0.89590032 0.90514386 0.90514386 0.88282648 0.84901584\n",
      " 0.84901584 0.92559244 0.82599067 0.79038167 0.79038167 0.65066136\n",
      " 0.53779388 0.29005733 0.29005733 0.13177663 0.10095713]\n",
      "137\n",
      "<class 'numpy.ndarray'>\n",
      "Data from video_2/features:\n",
      "[[-2.          0.35294127 -0.13333333 ...  1.4509804   1.2784314\n",
      "  -0.8078431 ]\n",
      " [ 0.13333344  0.6980393  -0.6196078  ...  0.682353    0.8078432\n",
      "   0.35294127]\n",
      " [ 0.18039227  0.5725491  -0.745098   ... -1.1686275   1.5294118\n",
      "   0.02352953]\n",
      " ...\n",
      " [-0.3843137   0.854902   -0.5098039  ... -0.19607842  1.137255\n",
      "   1.5921569 ]\n",
      " [-0.2745098   0.8078432  -0.52549016 ...  1.5137255   0.60392165\n",
      "   1.2313726 ]\n",
      " [-0.5098039   0.79215693 -0.572549   ...  1.2         1.7176471\n",
      "   0.05490208]]\n",
      "137\n",
      "<class 'numpy.ndarray'>\n",
      "Data from video_2/audio:\n",
      "[[ 0.6980393  -1.0588236  -0.5568627  ...  0.38431382 -1.8431373\n",
      "   0.35294127]\n",
      " [ 0.8235295  -0.83921564 -0.917647   ...  0.24313736 -1.1843138\n",
      "  -2.        ]\n",
      " [ 0.72941184 -0.54117644 -1.1686275  ...  1.9058824  -2.\n",
      "  -0.11764705]\n",
      " ...\n",
      " [ 0.60392165 -1.1529412  -0.60392153 ...  0.8078432  -2.\n",
      "  -1.3568628 ]\n",
      " [ 0.71372557 -0.9960784  -0.52549016 ... -0.03921568 -1.7960784\n",
      "  -1.4509804 ]\n",
      " [ 0.509804   -1.0431373  -0.65098035 ...  1.1843138  -0.9803921\n",
      "  -1.1058824 ]]\n",
      "137\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "file_path = 'preprocess/mr_hisum.h5'\n",
    "file='dataset/mr_hisum_audio.h5'\n",
    "def explore_h5_group(group, path=\"/\"):\n",
    "    \"\"\"遞迴列出 HDF5 群組內的所有鍵值\"\"\"\n",
    "    for key in group.keys():\n",
    "        item = group[key]\n",
    "        item_path = f\"{path}{key}\"\n",
    "        if isinstance(item, h5py.Group):  # 如果是群組\n",
    "            print(f\"Group: {item_path}\")\n",
    "            explore_h5_group(item, f\"{item_path}/\")  # 繼續遞迴\n",
    "        elif isinstance(item, h5py.Dataset):  # 如果是數據集\n",
    "            print(f\"Dataset: {item_path}, Shape: {item.shape}, Dtype: {item.dtype}\")\n",
    "n=2\n",
    "with h5py.File(file_path, 'r') as h5_file:\n",
    "    #explore_h5_group(h5_file)\n",
    "    dataset_name1 = f\"video_{n}/change_points\"  # 替換成檢查到的數據集路徑\n",
    "    data = h5_file[dataset_name1][:]\n",
    "    print(f\"Data from {dataset_name1}:\")\n",
    "    print(data)\n",
    "    print(data.shape)\n",
    "    print(type(data))\n",
    "    dataset_name2 = f\"video_{n}/gt_summary\"  # 替換成檢查到的數據集路徑\n",
    "    data = h5_file[dataset_name2][:]\n",
    "    print(f\"Data from {dataset_name2}:\")\n",
    "    print(data)\n",
    "    print(data.shape)\n",
    "    print(type(data))\n",
    "    dataset_name3 = f\"video_{n}/gtscore\"  # 替換成檢查到的數據集路徑\n",
    "    data = h5_file[dataset_name3][:]\n",
    "    print(f\"Data from {dataset_name3}:\")\n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    print(type(data))\n",
    "with h5py.File(file, 'r') as h5_file:\n",
    "    #explore_h5_group(h5_file)\n",
    "    dataset_name1 = f\"video_{n}/features\"  # 替換成檢查到的數據集路徑\n",
    "    data = h5_file[dataset_name1][:]\n",
    "    print(f\"Data from {dataset_name1}:\")\n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    print(type(data))\n",
    "    dataset_name2 = f\"video_{n}/audio\"  # 替換成檢查到的數據集路徑\n",
    "    data = h5_file[dataset_name2][:]\n",
    "    print(f\"Data from {dataset_name2}:\")\n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    print(type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5ec92-a303-48e3-8f56-4dc40bc5fb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrcopy",
   "language": "python",
   "name": "mrcopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
